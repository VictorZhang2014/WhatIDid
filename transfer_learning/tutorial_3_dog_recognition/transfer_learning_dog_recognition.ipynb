{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 基于 InceptionV3 的架构模型直接对狗的类别进行识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_bar(predictions):\n",
    "    types = [pred[1] for pred in predictions]\n",
    "    probs = [pred[2] for pred in predictions]\n",
    "    \n",
    "    plt.barh(np.arange(len(probs)), probs)\n",
    "    _ = plt.yticks(np.arange(3), types)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def load_img(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [(u'n02089867', u'Walker_hound', 0.9321249), (u'n02089973', u'English_foxhound', 0.063430324), (u'n02088364', u'beagle', 0.0043542106)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
    "\n",
    "def predicts_numbers():\n",
    "    model = InceptionV3(weights='imagenet')\n",
    "\n",
    "    img_path = \"dog_test.png\"\n",
    "    x = load_img(img_path)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "\n",
    "    predictions = decode_predictions(preds, top=3)[0]\n",
    "    print('Predicted: {}'.format(predictions))\n",
    "    plot_bar(predictions)\n",
    "  \n",
    "predicts_numbers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 基于 InceptionV3 的架构的迁移学习，对10种狗的类别进行识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 total dog categories.\n",
      "There are 722 total dog images.\n",
      "\n",
      "There are 578 training dog images.\n",
      "There are 71 validation dog images.\n",
      "There are 73 test dog images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# 定义函数来加载train，test和validation数据集\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), num_classes)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "# 加载train，test和validation数据集\n",
    "train_files, train_targets = load_dataset('dogImages/train')\n",
    "valid_files, valid_targets = load_dataset('dogImages/valid')\n",
    "test_files, test_targets = load_dataset('dogImages/test')\n",
    "\n",
    "# 加载狗品种列表\n",
    "dog_names = [item[20:-1] for item in sorted(glob(\"dogImages/train/*/\"))]\n",
    "\n",
    "# 打印数据统计描述\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training dog images.' % len(train_files))\n",
    "print('There are %d validation dog images.' % len(valid_files))\n",
    "print('There are %d test dog images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 578/578 [00:08<00:00, 64.66it/s]\n",
      "100%|██████████| 71/71 [00:01<00:00, 51.06it/s]\n",
      "100%|██████████| 73/73 [00:01<00:00, 65.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image   \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # 用PIL加载RGB图像为PIL.Image.Image类型\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # 将PIL.Image.Image类型转化为格式为(224, 224, 3)的3维张量\n",
    "    x = image.img_to_array(img)\n",
    "    # 将3维张量转化为格式为(1, 224, 224, 3)的4维张量并返回\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "                \n",
    "\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True   \n",
    "\n",
    "# Keras中的数据预处理过程\n",
    "train_tensors = paths_to_tensor(train_files).astype(np.float32)/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype(np.float32)/255\n",
    "test_tensors = paths_to_tensor(test_files).astype(np.float32)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(578, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(578, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victor/virtualenvlist/mydlp2/lib/python2.7/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 85s 9s/step - loss: 6.3703 - acc: 0.3102 - val_loss: 2.5822 - val_acc: 0.1127\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.58215, saving model to inceptin_v3.10dogs.weights.best.h5\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 88s 10s/step - loss: 2.2321 - acc: 0.5306 - val_loss: 2.3245 - val_acc: 0.1549\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.58215 to 2.32450, saving model to inceptin_v3.10dogs.weights.best.h5\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 88s 10s/step - loss: 2.3006 - acc: 0.6107 - val_loss: 2.3425 - val_acc: 0.1268\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.32450\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 89s 10s/step - loss: 1.0526 - acc: 0.7259 - val_loss: 2.5016 - val_acc: 0.1408\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.32450\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 90s 10s/step - loss: 2.1137 - acc: 0.6132 - val_loss: 2.7327 - val_acc: 0.0845\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.32450\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 100s 11s/step - loss: 0.7859 - acc: 0.7951 - val_loss: 2.4372 - val_acc: 0.0986\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.32450\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 92s 10s/step - loss: 1.1881 - acc: 0.7196 - val_loss: 2.4201 - val_acc: 0.1127\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.32450\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 92s 10s/step - loss: 1.2714 - acc: 0.6747 - val_loss: 2.4972 - val_acc: 0.1127\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.32450\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 92s 10s/step - loss: 0.6064 - acc: 0.8040 - val_loss: 2.4700 - val_acc: 0.0986\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.32450\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 92s 10s/step - loss: 1.5182 - acc: 0.6554 - val_loss: 2.4203 - val_acc: 0.1690\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.32450\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 40s 40s/step - loss: 0.5207 - acc: 0.7500 - val_loss: 2.3267 - val_acc: 0.0986\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 2.32450\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 31s 31s/step - loss: 0.4383 - acc: 0.8906 - val_loss: 2.3199 - val_acc: 0.0845\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.32450 to 2.31988, saving model to inceptin_v3.10dogs.weights.best.h5\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 30s 30s/step - loss: 0.4703 - acc: 0.8906 - val_loss: 2.3239 - val_acc: 0.1268\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.31988\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 33s 33s/step - loss: 0.3983 - acc: 0.8750 - val_loss: 2.3178 - val_acc: 0.1127\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.31988 to 2.31777, saving model to inceptin_v3.10dogs.weights.best.h5\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 32s 32s/step - loss: 0.1684 - acc: 0.9688 - val_loss: 2.3250 - val_acc: 0.1127\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.31777\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 21s 21s/step - loss: 3.0314 - acc: 0.5000 - val_loss: 2.3106 - val_acc: 0.1127\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.31777 to 2.31057, saving model to inceptin_v3.10dogs.weights.best.h5\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 32s 32s/step - loss: 0.4948 - acc: 0.8750 - val_loss: 2.3133 - val_acc: 0.1127\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.31057\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 35s 35s/step - loss: 0.5147 - acc: 0.8281 - val_loss: 2.3200 - val_acc: 0.1127\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.31057\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 33s 33s/step - loss: 0.3871 - acc: 0.8594 - val_loss: 2.3343 - val_acc: 0.1127\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.31057\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 34s 34s/step - loss: 0.4657 - acc: 0.8750 - val_loss: 2.3153 - val_acc: 0.1127\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.31057\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'plot_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-816e25f63c68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-816e25f63c68>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_classes, batch_size, epochs)\u001b[0m\n\u001b[1;32m    101\u001b[0m                       validation_data=validation_generator)\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0mplot_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_ft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'plot_training' is not defined"
     ]
    }
   ],
   "source": [
    "# 参考：\n",
    "# 迁移学习：https://keras.io/applications/\n",
    "# fit_generator: https://keras.io/preprocessing/image/\n",
    "# callback: https://keras.io/callbacks/\n",
    "\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def add_new_last_layers(base_model, num_classes):\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "    # and a logistic layer -- let's say we have num_classes classes\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(input=base_model.input, output=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "def freeze_previous_layers(model, base_model):\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def fine_tune_model(model):\n",
    "    # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "    # the first 249 layers and unfreeze the rest:\n",
    "    for layer in model.layers[:172]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[172:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  \n",
    "def plot_training(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r.')\n",
    "    plt.plot(epochs, val_acc, 'r')\n",
    "    plt.title('Training and validation accuracy')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r.')\n",
    "    plt.plot(epochs, val_loss, 'r-')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.show()\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='inceptin_v3.10dogs.weights.best1.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "def train(num_classes, batch_size, epochs):\n",
    "  \n",
    "    # data prep\n",
    "    train_datagen = ImageDataGenerator(\n",
    "      preprocessing_function=preprocess_input,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True\n",
    "    )\n",
    "    valid_datagen = ImageDataGenerator(\n",
    "      preprocessing_function=preprocess_input,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    # data augmentation\n",
    "    train_generator = train_datagen.flow(train_tensors, train_targets, batch_size=batch_size)\n",
    "    validation_generator = valid_datagen.flow(valid_tensors, valid_targets, batch_size=batch_size)\n",
    "\n",
    "    # setup model\n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False) # include_top=False denotes that excludes final FC layer \n",
    "    model = add_new_last_layers(base_model, num_classes)\n",
    "\n",
    "    # transfer learning\n",
    "    freeze_previous_layers(model, base_model)\n",
    "\n",
    "    print(\"First fitting the generator.\")\n",
    "    # train the model on the new data for a few epochs\n",
    "    history_tl = model.fit_generator(train_generator, \n",
    "                      steps_per_epoch=train_tensors.shape[0] / batch_size, \n",
    "                      epochs=epochs,\n",
    "                      verbose=1, \n",
    "                      callbacks=[checkpointer], \n",
    "                      validation_data=validation_generator)\n",
    "\n",
    "    # fine tune\n",
    "    fine_tune_model(model)\n",
    "\n",
    "    print(\"Second fitting the generator.\")\n",
    "    # we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "    # alongside the top Dense layers\n",
    "    history_ft = model.fit_generator(train_generator, \n",
    "                      steps_per_epoch=valid_tensors.shape[0] / batch_size, \n",
    "                      epochs=epochs,\n",
    "                      verbose=1, \n",
    "                      callbacks=[checkpointer], \n",
    "                      validation_data=validation_generator)\n",
    "\n",
    "\n",
    "    # https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "    # serialize model to YAML\n",
    "    model_yaml = model.to_yaml()\n",
    "    with open(\"inceptin_v3_10dogs_weights_best.yaml\", \"w\") as yaml_file:\n",
    "        yaml_file.write(model_yaml)\n",
    "    # serialize weights to HDF5 \n",
    "    model.save_weights(\"inceptin_v3_10dogs_weights_best.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "    plot_training(history_ft)\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 1\n",
    "train(num_classes, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过hdf5权重来加载InceptionV3的迁移学习模型\n",
    "\n",
    "> HDF5文件是用来保存模型的权重\n",
    "\n",
    "预测步骤：\n",
    "- 1.创建模型架构，从InceptionV3桥接过来的\n",
    "- 2.加载模型权重\n",
    "- 3.预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victor/virtualenvlist/mydlp2/lib/python2.7/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 18s 249ms/step\n",
      "Test loss: 31.04. Test acc: 87.67.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False,input_shape=test_tensors.shape[1:]) \n",
    "trained_model = add_new_last_layers(base_model, 10)\n",
    "\n",
    "trained_model.load_weights(\"inceptin_v3.10dogs.weights.best.h5\") # load weights into new model\n",
    "trained_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "#trained_model.summary()\n",
    "\n",
    "score = trained_model.evaluate(test_tensors, test_targets, verbose=1)\n",
    "print(\"Test {}: {:.2f}. Test {}: {:.2f}.\".format(trained_model.metrics_names[0], \n",
    "                                                 score[0]*100, \n",
    "                                                 trained_model.metrics_names[1], \n",
    "                                                 score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [[1.8175404e-05 8.1746082e-05 1.1727394e-05 6.1724364e-05 1.2665604e-05\n",
      "  1.7824543e-05 9.9977142e-01 1.6615742e-05 3.7802827e-06 4.3137570e-06]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 预测真实狗狗的图片\n",
    "\n",
    "def load_dog_img(trained_model):\n",
    "    img_path = 'dog_test.png' #'dogImages/test/007.American_foxhound/American_foxhound_00519.jpg'\n",
    "    x = load_img(img_path)\n",
    "    x = preprocess_input(x)\n",
    "    predictions = trained_model.predict(x)\n",
    "\n",
    "    #predictions = decode_predictions(predictions, top=10)\n",
    "    print('Predicted: {}'.format(predictions))\n",
    "\n",
    "    plt.barh(np.arange(10), predictions[0])\n",
    "    _ = plt.yticks(np.arange(10), dog_names)\n",
    "    plt.show()\n",
    "\n",
    "load_dog_img(trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过.yaml文件和.hdf5文件来加载InceptionV3的迁移学习模型\n",
    "\n",
    "> yaml文件和json文件都可以保存模型的架构\n",
    "\n",
    "> HDF5文件用来保存模型的权重\n",
    "\n",
    "预测步骤：\n",
    "- 1.加载模型架构\n",
    "- 2.加载模型权重\n",
    "- 3.预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 13s 176ms/step\n",
      "Test loss: 31.04. Test acc: 87.67.\n"
     ]
    }
   ],
   "source": [
    "# 验证\n",
    "\n",
    "# https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "\n",
    "# load YAML and create model\n",
    "with open('model.yaml', 'r') as yaml_file:\n",
    "  loaded_model_yaml = yaml_file.read()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
